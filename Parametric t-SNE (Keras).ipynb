{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.15 s, sys: 551 ms, total: 1.7 s\n",
      "Wall time: 1.7 s\n",
      "(60000, 'train samples')\n",
      "(10000, 'test samples')\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "\n",
    "%time (X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "X_train = X_train.reshape(60000, 784)\n",
    "X_test = X_test.reshape(10000, 784)\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 563 Âµs, sys: 1.46 s, total: 1.46 s\n",
      "Wall time: 1.46 s\n"
     ]
    }
   ],
   "source": [
    "%time P = np.load('P.npy') # load pre-computed joint probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import skflow\n",
    "\n",
    "eps = 10e-8\n",
    "\n",
    "def tsne_model(X, P):\n",
    "    d = 2\n",
    "    activations = skflow.ops.dnn(X, [500, 500, 2000, d], activation=tf.nn.relu) \n",
    "    v = d - 1.\n",
    "    sum_act = tf.reduce_sum(tf.square(activations), reduction_indices=1)\n",
    "    Q = tf.reshape(sum_act, [-1, 1]) + -2 * tf.matmul(activations, tf.transpose(activations))\n",
    "    Q = (sum_act + Q) / v\n",
    "    Q = tf.pow(1 + Q, -(v + 1) / 2)\n",
    "    Q *= 1 - tf.identity(Q) # set the diagonal to zero..?\n",
    "    Q /= tf.reduce_sum(Q)\n",
    "    Q = tf.maximum(Q, eps)\n",
    "    C = tf.log((P + eps) / (Q + eps))\n",
    "    C = tf.reduce_sum(P * C)\n",
    "    return activations, C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "classifier = skflow.TensorFlowEstimator(\n",
    "    n_classes=0,\n",
    "    model_fn=tsne_model,\n",
    "    batch_size=batch_size,\n",
    "    steps=1*batch_size,\n",
    "    learning_rate=0.001\n",
    ")\n",
    "classifier.fit(X_train, P.reshape(-1, batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using gpu device 0: GeForce GT 750M (CNMeM is enabled with initial size: 75.0% of memory, CuDNN 4007)\n",
      "/usr/local/lib/python2.7/site-packages/theano/tensor/signal/downsample.py:5: UserWarning: downsample module has been moved to the pool module.\n",
      "  warnings.warn(\"downsample module has been moved to the pool module.\")\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import np_utils\n",
    "from keras.objectives import categorical_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import theano\n",
    "from theano.tensor.extra_ops import fill_diagonal\n",
    "from keras import backend as K\n",
    "\n",
    "# P is the joint probabilities for this batch (Keras loss functions call this y_true)\n",
    "# activations is the low-dimensional output (Keras loss functions call this y_pred)\n",
    "def tsne(P, activations):\n",
    "    # v = length(network{end}.bias_upW) - 1\n",
    "#     v = K.shape(activations)[1] - 1. # using this is much slower than setting a constant\n",
    "    v = 2. - 1. # d = 2\n",
    "    \n",
    "    # sum_act = sum(activations .^ 2, 2) # usually matlab sums are along the first axis\n",
    "    sum_act = K.sum(K.square(activations), axis=1)\n",
    "    # Q = (1 + (bsxfun(@plus, sum_act, bsxfun(@plus, sum_act', -2 * activations * activations')) ./ v)) .^ -((v + 1) / 2)\n",
    "    Q = K.reshape(sum_act, [-1, 1]) + -2 * K.dot(activations, K.transpose(activations))\n",
    "    Q = (sum_act + Q) / v\n",
    "    Q = K.pow(1 + Q, -(v + 1) / 2)\n",
    "    # Q(1:n+1:end) = 0\n",
    "    fill_diagonal(Q, 0) # Theano-only\n",
    "    # Q = Q ./ sum(Q(:)) # sum(Q(:)) means \"sum all elements in Q\" http://es.mathworks.com/matlabcentral/newsreader/view_thread/51252\n",
    "    Q /= K.sum(Q)\n",
    "    # Q = max(Q, eps);\n",
    "    Q = K.maximum(Q, K.epsilon())\n",
    "    # C = sum(sum(P{1} .* log((P{1} + eps) ./ (Q + eps)))) # sum(sum(A)) also means sum all elements\n",
    "    C = K.log((P + K.epsilon()) / (Q + K.epsilon()))\n",
    "    C = K.sum(P * C)\n",
    "    return C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.67 s, sys: 70.1 ms, total: 2.74 s\n",
      "Wall time: 2.73 s\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(500, input_shape=(784,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(500))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(2000))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(2))\n",
    "\n",
    "sgd = SGD(lr=100) # even with a huge learning rate the loss doesn't seem to change?\n",
    "%time model.compile(loss=tsne, optimizer=sgd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(60000, 5000)\n"
     ]
    }
   ],
   "source": [
    "Y_train = P.reshape(X_train.shape[0], -1)\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!mkdir -p plotter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import gc\n",
    "from matplotlib import pyplot as plt\n",
    "import keras\n",
    "class Plotter(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.batch = 0\n",
    "        \n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        prediction = self.model.predict(X_test)\n",
    "        fig = plt.figure(figsize=(8,8))\n",
    "        plt.scatter(prediction[:,0], prediction[:,1], alpha=1, marker='o', s=3, edgecolor='', c=y_test)\n",
    "        ax = fig.gca()\n",
    "        ax.set_autoscale_on(False)\n",
    "        fig.tight_layout()\n",
    "        plt.savefig('plotter/%04d.png' % (self.batch+1), pad_inches=0)\n",
    "        plt.close()\n",
    "        gc.collect()\n",
    "        self.batch += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "60000/60000 [==============================] - 7s - loss: 3.4809     \n",
      "Epoch 2/4\n",
      "60000/60000 [==============================] - 7s - loss: 3.4809     \n",
      "Epoch 3/4\n",
      "60000/60000 [==============================] - 7s - loss: 3.4809     \n",
      "Epoch 4/4\n",
      "60000/60000 [==============================] - 7s - loss: 3.4809     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x11fab9890>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, Y_train,\n",
    "          batch_size=batch_size,\n",
    "#           callbacks=[Plotter()],\n",
    "          shuffle=False,\n",
    "          nb_epoch=4,\n",
    "          verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
